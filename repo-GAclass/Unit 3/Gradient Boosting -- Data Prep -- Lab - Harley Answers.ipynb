{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab -- Data Prep & Gradient Boosting\n",
    "\n",
    "Welcome to today's lab!  Today we're going to shift our attention to a more demanding dataset -- the restaurants data.  A quarter million rows, dates, and categorical data make this a more interesting, realistic use case of boosting.  \n",
    "\n",
    "The point of today's lab will be to experiment with different encoding methods and model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:**  Load in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>genre</th>\n",
       "      <th>area</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252103</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>49</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252104</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>60</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252105</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>69</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252106</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252107</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252108 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id visit_date  visitors calendar_date day_of_week  \\\n",
       "0       air_ba937bf13d40fb24 2016-01-13        25    2016-01-13   Wednesday   \n",
       "1       air_ba937bf13d40fb24 2016-01-14        32    2016-01-14    Thursday   \n",
       "2       air_ba937bf13d40fb24 2016-01-15        29    2016-01-15      Friday   \n",
       "3       air_ba937bf13d40fb24 2016-01-16        22    2016-01-16    Saturday   \n",
       "4       air_ba937bf13d40fb24 2016-01-18         6    2016-01-18      Monday   \n",
       "...                      ...        ...       ...           ...         ...   \n",
       "252103  air_a17f0778617c76e2 2017-04-21        49    2017-04-21      Friday   \n",
       "252104  air_a17f0778617c76e2 2017-04-22        60    2017-04-22    Saturday   \n",
       "252105  air_a17f0778617c76e2 2017-03-26        69    2017-03-26      Sunday   \n",
       "252106  air_a17f0778617c76e2 2017-03-20        31    2017-03-20      Monday   \n",
       "252107  air_a17f0778617c76e2 2017-04-09        26    2017-04-09      Sunday   \n",
       "\n",
       "        holiday           genre                          area   latitude  \\\n",
       "0             0      Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "1             0      Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2             0      Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "3             0      Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "4             0      Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "...         ...             ...                           ...        ...   \n",
       "252103        0  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri  34.695124   \n",
       "252104        0  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri  34.695124   \n",
       "252105        0  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri  34.695124   \n",
       "252106        1  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri  34.695124   \n",
       "252107        0  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri  34.695124   \n",
       "\n",
       "         longitude  reserve_visitors  \n",
       "0       139.751599               0.0  \n",
       "1       139.751599               0.0  \n",
       "2       139.751599               0.0  \n",
       "3       139.751599               0.0  \n",
       "4       139.751599               0.0  \n",
       "...            ...               ...  \n",
       "252103  135.197852               6.0  \n",
       "252104  135.197852              37.0  \n",
       "252105  135.197852              35.0  \n",
       "252106  135.197852               3.0  \n",
       "252107  135.197852              32.0  \n",
       "\n",
       "[252108 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import datetime as dt\n",
    "df = pd.read_csv('/Users/harleyhoffmann/dat-02-22/ClassMaterial/Unit2/data/master.csv', parse_dates=['visit_date', 'calendar_date'])\n",
    "df['reserve_visitors'] = df['reserve_visitors'].fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Create a training and test set.\n",
    "\n",
    "Make the test set the **last 15 observations for each restaurant**.\n",
    "\n",
    "Turn each of these variables into `X_train, y_train`, and `X_test, y_test`, respectively.\n",
    "\n",
    "**Hint:**  This harkens back to our grouping lab -- check this if you forget how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract time pieces from the calendar date column\n",
    "df['month'] = pd.DatetimeIndex(df['calendar_date']).month\n",
    "df['year'] = pd.DatetimeIndex(df['calendar_date']).year\n",
    "df['day_of_month'] = pd.DatetimeIndex(df['calendar_date']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "df.sort_values(by=['id','visit_date'], ascending=True, inplace=True)\n",
    "\n",
    "train = df.groupby('id').apply(lambda x: x.iloc[:-15])\n",
    "test = df.groupby('id').apply(lambda x: x.iloc[-15:])\n",
    "\n",
    "#we're dropping the dates because we moved them into new columns\n",
    "train.drop('visit_date', axis=1, inplace=True)\n",
    "test.drop('visit_date', axis=1, inplace=True)\n",
    "\n",
    "train.drop('calendar_date', axis=1, inplace=True)\n",
    "test.drop('calendar_date', axis=1, inplace=True)\n",
    "\n",
    "#we're predicting visitors so that becomes they variable\n",
    "X_train, y_train = train.drop('visitors', axis=1), train['visitors']\n",
    "X_test, y_test   = test.drop('visitors', axis=1), test['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Experiment with different encoding methods\n",
    "\n",
    "Let's do a quick check to see how different encoding methods work out of the box on our dataset.\n",
    "\n",
    "You're going to repeat the same process for each of `OrdinalEncoder`, `TargetEncoder`, and `OneHotEncoder` and see which one gives you the best results on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a:** Use an `OrdinalEncoder` to transform your training set with the `fit_transform` method.  Then use the `transform` method to transform your test set.  \n",
    "\n",
    "**Important:** An important detail here is that the test set is being transformed according to the values in your training set.  \n",
    "\n",
    "If you are confused about how the transformation is happening, try using the `mapping()` method on your category encoder to get a hang of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinal encoder - numbers\n",
    "ore = ce.OrdinalEncoder()\n",
    "X_train_ore = ore.fit_transform(X_train)\n",
    "X_test_ore  = ore.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b:** Initialize a `GradientBoostingRegressor` with the default parameters, fit it on your training set, and score it on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17427166552896078, 0.15682702382071445)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "gbm = GradientBoostingRegressor()\n",
    "gbm.fit(X_train_ore, y_train)\n",
    "gbm.score(X_train_ore, y_train), gbm.score(X_test_ore, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c:** Repeat these same steps for the `TargetEncoder` and the `OneHotEncoder`\n",
    "\n",
    "**Important:** The `OneHotEncoder` can take awhile to fit.  If nothing happens in around 4 minutes, just cancel the process and try it again later on when you have more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Target Encoder - floats?\n",
    "te = ce.TargetEncoder()\n",
    "X_train_te = te.fit_transform(X_train, y_train)\n",
    "X_test_te  = te.transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47645123730015393, 0.4649839906056512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor()\n",
    "gbm.fit(X_train_te, y_train)\n",
    "gbm.score(X_train_te, y_train), gbm.score(X_test_te, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#onehotencoder - binary\n",
    "ohe      = ce.OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(X_train, y_train)\n",
    "X_test_ohe  = ohe.transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16940288952649096, 0.17191414257277793)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor()\n",
    "gbm.fit(X_train_ohe, y_train)\n",
    "gbm.score(X_train_ohe, y_train), gbm.score(X_test_ohe, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Look at your most important features\n",
    "\n",
    "Similar to the previous lab, take your model's most important features and load them into a dataframe to see what's driving your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47645123730015393, 0.4649839906056512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the Target encoder because it had the best score\n",
    "te = ce.TargetEncoder()\n",
    "X_train_te = te.fit_transform(X_train, y_train)\n",
    "X_test_te  = te.transform(X_test, y_test)\n",
    "#fitting and scoring\n",
    "gbm = GradientBoostingRegressor()\n",
    "gbm.fit(X_train_te, y_train)\n",
    "gbm.score(X_train_te, y_train), gbm.score(X_test_te, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0.864960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>0.100339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month</td>\n",
       "      <td>0.011479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>holiday</td>\n",
       "      <td>0.006557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>day_of_month</td>\n",
       "      <td>0.005928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reserve_visitors</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genre</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>area</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "0                 id    0.864960\n",
       "1        day_of_week    0.100339\n",
       "8              month    0.011479\n",
       "2            holiday    0.006557\n",
       "10      day_of_month    0.005928\n",
       "6          longitude    0.004103\n",
       "5           latitude    0.003187\n",
       "7   reserve_visitors    0.001052\n",
       "3              genre    0.001028\n",
       "4               area    0.000813\n",
       "9               year    0.000553"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here for feature importances\n",
    "feats = pd.DataFrame({'Feature':X_train_te.columns, 'Importance':gbm.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Can model parameters improve your score?  \n",
    "\n",
    "Take the **best** version of your encoding method and try changing some parameters with your model to see if it improves your score.  \n",
    "\n",
    "You won't have a ton of time to do this, but try some of the following:\n",
    "\n",
    " - Try increasing the number of trees your model uses -- 250, 500, or perhaps more trees if time permits\n",
    " - Try experimenting with differing values for tree depth -- the default is 3, but perhaps 4, 5 or 6 works better\n",
    " - Try improving fitting time by introducing some **randomness** into your data with the following two model parameters:\n",
    "   - `subsample`: this dictates what proportion of your data will be used for each tree.  A value of `0.7` means 70% of your data will be used for a particular tree, chosen at random\n",
    "   - `max_features`: this is the portion of columns that are used at each individual split.  If you enter an integer the model will randomly select that number of columns, if you enter a decimal it will randomly select that portion of columns.\n",
    "   - It can be very useful to find the most sparse model that will still give you comparable results.  Ie, if you find a gbm with 500 trees and a max_depth of 4 gives you the best results, it can be very beneficial if you can get those same results with a `subsample` value of 0.6 and a `max_features` score of 0.7, because your model will fit ~50% faster.\n",
    "   \n",
    "This step is open ended, so we will likely have to end class in the middle of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'ls',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "gbm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5697688176016562, 0.5262781000975406)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the Target encoder because it had the best score\n",
    "te = ce.TargetEncoder()\n",
    "X_train_te = te.fit_transform(X_train, y_train)\n",
    "X_test_te  = te.transform(X_test, y_test)\n",
    "#fitting and scoring\n",
    "gbm = GradientBoostingRegressor(n_estimators=500, max_depth=5, subsample=0.6, max_features=0.7)\n",
    "gbm.fit(X_train_te, y_train)\n",
    "gbm.score(X_train_te, y_train), gbm.score(X_test_te, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
